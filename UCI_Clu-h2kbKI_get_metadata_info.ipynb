{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Information from Metadata\n",
    "https://www.synapse.org/Synapse:syn65941775"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== BIOSPECIMEN DATAFRAME ===\n",
      "Shape: 114 rows x 17 columns\n",
      "Columns: ['individualID', 'specimenID', 'specimenIdSource', 'organ', 'tissue', 'BrodmannArea', 'sampleStatus', 'tissueWeight', 'tissueVolume', 'nucleicAcidSource', 'cellType', 'fastingState', 'isPostMortem', 'samplingAge', 'samplingAgeUnits', 'visitNumber', 'assay']\n",
      "Number of unique individualIDs: 77\n",
      "Number of rows with missing individualID: 0\n",
      "\n",
      "=== INDIVIDUAL DATAFRAME ===\n",
      "Shape: 77 rows x 27 columns\n",
      "Columns: ['individualID', 'climbID', 'microchipID', 'birthID', 'matingID', 'individualIdSource', 'materialOrigin', 'sex', 'species', 'generation', 'dateBirth', 'ageDeath', 'ageDeathUnits', 'brainWeight', 'rodentWeight', 'rodentDiet', 'bedding', 'room', 'waterpH', 'treatmentDose', 'treatmentType', 'stockNumber', 'genotype', 'genotypeBackground', 'individualCommonGenotype', 'modelSystemName', 'officialName']\n",
      "Number of unique individualIDs: 77\n",
      "Number of rows with missing individualID: 0\n",
      "\n",
      "=== RNASEQMETADATA DATAFRAME ===\n",
      "Shape: 114 rows x 25 columns\n",
      "Columns: ['Component', 'specimenID', 'libraryID', 'assay', 'platform', 'RIN', 'referenceSet', 'rnaBatch', 'libraryBatch', 'sequencingBatch', 'libraryPrep', 'libraryPreparationMethod', 'libraryVersion', 'isStranded', 'readStrandOrigin', 'readLength', 'runType', 'totalReads', 'validBarcodeReads', 'DV200', 'inputTotalRNA', 'ribosomalDepletion', 'globinRemoval', 'Unnamed: 23', 'Unnamed: 24']\n",
      "'individualID' column not found.\n"
     ]
    }
   ],
   "source": [
    "# Read in the data\n",
    "biospecimen = pd.read_csv(\"UCI_Clu-rs2279590_h2kb_biospecimen_metadata.csv\")\n",
    "individual = pd.read_csv(\"UCI_Clu-rs2279590_h2kb_IndividualID.csv\")\n",
    "rnaseqmetadata = pd.read_csv(\"UCI_Clu-rs2279590_h2kb-AssayRnaSeqMetadata.csv\")\n",
    "\n",
    "# Drop empty rows (all-NaN) for each dataframe\n",
    "biospecimen = biospecimen.dropna(how='all')\n",
    "individual = individual.dropna(how='all')\n",
    "rnaseqmetadata = rnaseqmetadata.dropna(how='all')\n",
    "\n",
    "\n",
    "# Print basic info for each dataframe\n",
    "for name, df in [(\"biospecimen\", biospecimen), (\"individual\", individual), (\"rnaseqmetadata\", rnaseqmetadata)]:\n",
    "    print(f\"\\n=== {name.upper()} DATAFRAME ===\")\n",
    "    print(f\"Shape: {df.shape[0]} rows x {df.shape[1]} columns\")\n",
    "    print(f\"Columns: {list(df.columns)}\")\n",
    "    if 'individualID' in df.columns:\n",
    "        print(f\"Number of unique individualIDs: {df['individualID'].nunique()}\")\n",
    "        print(f\"Number of rows with missing individualID: {df['individualID'].isna().sum()}\")\n",
    "    else:\n",
    "        print(\"'individualID' column not found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== MERGED DATAFRAME INFO ===\n",
      "Shape: 114 rows x 67 columns\n",
      "Columns: ['individualID', 'specimenID', 'specimenIdSource', 'organ', 'tissue', 'BrodmannArea', 'sampleStatus', 'tissueWeight', 'tissueVolume', 'nucleicAcidSource', 'cellType', 'fastingState', 'isPostMortem', 'samplingAge', 'samplingAgeUnits', 'visitNumber', 'assay_x', 'climbID', 'microchipID', 'birthID', 'matingID', 'individualIdSource', 'materialOrigin', 'sex', 'species', 'generation', 'dateBirth', 'ageDeath', 'ageDeathUnits', 'brainWeight', 'rodentWeight', 'rodentDiet', 'bedding', 'room', 'waterpH', 'treatmentDose', 'treatmentType', 'stockNumber', 'genotype', 'genotypeBackground', 'individualCommonGenotype', 'modelSystemName', 'officialName', 'Component', 'libraryID', 'assay_y', 'platform', 'RIN', 'referenceSet', 'rnaBatch', 'libraryBatch', 'sequencingBatch', 'libraryPrep', 'libraryPreparationMethod', 'libraryVersion', 'isStranded', 'readStrandOrigin', 'readLength', 'runType', 'totalReads', 'validBarcodeReads', 'DV200', 'inputTotalRNA', 'ribosomalDepletion', 'globinRemoval', 'Unnamed: 23', 'Unnamed: 24']\n",
      "Number of unique individualIDs: 77\n",
      "Number of rows with missing individualID: 0\n",
      "Number of unique specimenIDs: 114\n",
      "Number of rows with missing specimenID: 0\n",
      "\n",
      "First 5 rows of merged_df:\n",
      "   individualID specimenID specimenIdSource  organ       tissue  BrodmannArea  \\\n",
      "0       11615.0    11615lh          UCI_TMF  brain  hippocampus           NaN   \n",
      "1       11616.0    11616lh          UCI_TMF  brain  hippocampus           NaN   \n",
      "2       11617.0    11617lh          UCI_TMF  brain  hippocampus           NaN   \n",
      "3       11625.0    11625lh          UCI_TMF  brain  hippocampus           NaN   \n",
      "4       11626.0    11626lh          UCI_TMF  brain  hippocampus           NaN   \n",
      "\n",
      "  sampleStatus  tissueWeight  tissueVolume nucleicAcidSource  ...  \\\n",
      "0       frozen           NaN           NaN         bulk cell  ...   \n",
      "1       frozen           NaN           NaN         bulk cell  ...   \n",
      "2       frozen           NaN           NaN         bulk cell  ...   \n",
      "3       frozen           NaN           NaN         bulk cell  ...   \n",
      "4       frozen           NaN           NaN         bulk cell  ...   \n",
      "\n",
      "        readLength    runType totalReads  validBarcodeReads DV200  \\\n",
      "0  R1:150 ; R2:150  pairedEnd        NaN                NaN   NaN   \n",
      "1  R1:150 ; R2:150  pairedEnd        NaN                NaN   NaN   \n",
      "2  R1:150 ; R2:150  pairedEnd        NaN                NaN   NaN   \n",
      "3  R1:150 ; R2:150  pairedEnd        NaN                NaN   NaN   \n",
      "4  R1:150 ; R2:150  pairedEnd        NaN                NaN   NaN   \n",
      "\n",
      "   inputTotalRNA ribosomalDepletion  globinRemoval  Unnamed: 23 Unnamed: 24  \n",
      "0            NaN                NaN            NaN          NaN         NaN  \n",
      "1            NaN                NaN            NaN          NaN         NaN  \n",
      "2            NaN                NaN            NaN          NaN         NaN  \n",
      "3            NaN                NaN            NaN          NaN         NaN  \n",
      "4            NaN                NaN            NaN          NaN         NaN  \n",
      "\n",
      "[5 rows x 67 columns]\n"
     ]
    }
   ],
   "source": [
    "# Merge the dataframes\n",
    "\n",
    "merged1_df = pd.merge(biospecimen, individual, on='individualID', how='outer')\n",
    "merged_df = pd.merge(merged1_df, rnaseqmetadata, on='specimenID', how='outer')\n",
    "\n",
    "print(\"\\n=== MERGED DATAFRAME INFO ===\")\n",
    "print(f\"Shape: {merged_df.shape[0]} rows x {merged_df.shape[1]} columns\")\n",
    "print(f\"Columns: {list(merged_df.columns)}\")\n",
    "\n",
    "if 'individualID' in merged_df.columns:\n",
    "    print(f\"Number of unique individualIDs: {merged_df['individualID'].nunique()}\")\n",
    "    print(f\"Number of rows with missing individualID: {merged_df['individualID'].isna().sum()}\")\n",
    "else:\n",
    "    print(\"'individualID' column not found in merged_df.\")\n",
    "\n",
    "if 'specimenID' in merged_df.columns:\n",
    "    print(f\"Number of unique specimenIDs: {merged_df['specimenID'].nunique()}\")\n",
    "    print(f\"Number of rows with missing specimenID: {merged_df['specimenID'].isna().sum()}\")\n",
    "else:\n",
    "    print(\"'specimenID' column not found in merged_df.\")\n",
    "\n",
    "print(\"\\nFirst 5 rows of merged_df:\")\n",
    "print(merged_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unique entries in 'tissue' column:\n",
      "- hippocampus\n",
      "- cerebral cortex\n",
      "\n",
      "Total unique tissues: 2\n",
      "\n",
      "Unique entries in 'genotype' column:\n",
      "- 5XFAD_carrier\n",
      "- 5XFAD_noncarrier\n",
      "- 5XFAD_carrier, Clu-rs2279590_KI_homozygous\n",
      "- Clu-rs2279590_KI_homozygous\n",
      "\n",
      "Total unique genotypes: 4\n"
     ]
    }
   ],
   "source": [
    "# Just looking at some stuff, not neccessary to run\n",
    "# Print unique entries for the \"tissue\" column in merged_df\n",
    "if \"tissue\" in merged_df.columns:\n",
    "    unique_tissues = merged_df[\"tissue\"].dropna().unique()\n",
    "    print(\"\\nUnique entries in 'tissue' column:\")\n",
    "    for t in unique_tissues:\n",
    "        print(f\"- {t}\")\n",
    "    print(f\"\\nTotal unique tissues: {len(unique_tissues)}\")\n",
    "else:\n",
    "    print(\"'tissue' column not found in merged_df.\")\n",
    "\n",
    "# Print unique entries for the \"genotype\" column in merged_df\n",
    "if \"genotype\" in merged_df.columns:\n",
    "    unique_genotypes = merged_df[\"genotype\"].dropna().unique()\n",
    "    print(\"\\nUnique entries in 'genotype' column:\")\n",
    "    for g in unique_genotypes:\n",
    "        print(f\"- {g}\")\n",
    "    print(f\"\\nTotal unique genotypes: {len(unique_genotypes)}\")\n",
    "else:\n",
    "    print(\"'genotype' column not found in merged_df.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== GROUPED COUNTS BY ageDeath, sex, genotype ===\n",
      "    ageDeath     sex                                    genotype  count\n",
      "0        4.0  female                               5XFAD_carrier      5\n",
      "1        4.0  female  5XFAD_carrier, Clu-rs2279590_KI_homozygous      4\n",
      "2        4.0  female                            5XFAD_noncarrier      3\n",
      "3        4.0  female                 Clu-rs2279590_KI_homozygous      5\n",
      "4        4.0    male                               5XFAD_carrier      5\n",
      "5        4.0    male  5XFAD_carrier, Clu-rs2279590_KI_homozygous      5\n",
      "6        4.0    male                            5XFAD_noncarrier      5\n",
      "7        4.0    male                 Clu-rs2279590_KI_homozygous      5\n",
      "8       12.0  female                               5XFAD_carrier     10\n",
      "9       12.0  female  5XFAD_carrier, Clu-rs2279590_KI_homozygous      9\n",
      "10      12.0  female                            5XFAD_noncarrier     10\n",
      "11      12.0  female                 Clu-rs2279590_KI_homozygous      9\n",
      "12      12.0    male                               5XFAD_carrier     10\n",
      "13      12.0    male  5XFAD_carrier, Clu-rs2279590_KI_homozygous     10\n",
      "14      12.0    male                            5XFAD_noncarrier      9\n",
      "15      12.0    male                 Clu-rs2279590_KI_homozygous     10\n",
      "\n",
      "Number of unique groups: 16\n"
     ]
    }
   ],
   "source": [
    "# GET THE DATA FOR THE SPREADSHEET (https://docs.google.com/spreadsheets/d/11vmntFrno9ubNMOE8bbMejEROPygmeJZ/edit?pli=1&gid=757405125#gid=757405125)\n",
    "# Group merged_df by \"ageDeath\", \"sex\", and \"genotype\" and count the number of rows in each group\n",
    "grouped = merged_df.groupby([\"ageDeath\", \"sex\", \"genotype\"]).size().reset_index(name='count')\n",
    "\n",
    "print(\"\\n=== GROUPED COUNTS BY ageDeath, sex, genotype ===\")\n",
    "print(grouped)\n",
    "\n",
    "print(f\"\\nNumber of unique groups: {grouped.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate Metadata\n",
    "Look at the actual RNAseq data and make sure that all samples exist and align with what is stated in the metadata.\n",
    "\n",
    "https://www.synapse.org/Synapse:syn65941772"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In terminal, run:\n",
    "# synapse list syn65941772 > UCI_Clu-h2kbKI_rnaseqdata_list.csv\n",
    "\n",
    "df = pd.read_csv(\"UCI_Clu-h2kbKI_rnaseqdata_list.csv\", header=None, names=[\"syn_id\", \"file_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the filename to get the metadata\n",
    "def parse_filename(fname):\n",
    "    # Split by underscore\n",
    "    parts = str(fname).split(\"_\")\n",
    "    # Defensive: if not enough parts, return Nones\n",
    "    if len(parts) < 7:\n",
    "        return {\n",
    "            \"lane\": None,\n",
    "            \"tissue\": None,\n",
    "            \"sex\": None,\n",
    "            \"genotype\": None,\n",
    "            \"age\": None,\n",
    "            \"individualID\": None,\n",
    "            \"read\": None\n",
    "        }\n",
    "    # Find the index of the sex (first \"M\" or \"F\")\n",
    "    try:\n",
    "        sex_idx = next(i for i, p in enumerate(parts) if p in (\"M\", \"F\"))\n",
    "    except StopIteration:\n",
    "        sex_idx = 2  # fallback, but may be wrong\n",
    "    # Find the index of the age (endswith \"mo\")\n",
    "    try:\n",
    "        age_idx = next(i for i, p in enumerate(parts) if p.endswith(\"mo\"))\n",
    "    except StopIteration:\n",
    "        age_idx = sex_idx + 2  # fallback\n",
    "    # Find the index of the individualID (should be after age)\n",
    "    try:\n",
    "        indiv_idx = age_idx + 1\n",
    "        individualID = parts[indiv_idx]\n",
    "    except IndexError:\n",
    "        individualID = None\n",
    "    # Read is always the last part before extension, e.g. ..._1.fq.gz or ..._2.fq.gz\n",
    "    read_part = parts[-1]\n",
    "    # If read_part contains a dot, split and take the first part (e.g. \"1.fq.gz\" -> \"1\")\n",
    "    read = read_part.split(\".\")[0]\n",
    "    # Genotype is everything between sex and age\n",
    "    genotype = \"_\".join(parts[sex_idx + 1:age_idx])\n",
    "    return {\n",
    "        \"lane\": parts[0],\n",
    "        \"tissue\": parts[1],\n",
    "        \"sex\": parts[sex_idx],\n",
    "        \"genotype\": genotype,\n",
    "        \"age\": parts[age_idx],\n",
    "        \"individualID\": individualID,\n",
    "        \"read\": read\n",
    "    }\n",
    "\n",
    "parsed = df[\"file_name\"].apply(parse_filename)\n",
    "parsed_df = pd.DataFrame(parsed.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure all samples have both read1 and read2\n",
    "# For each unique sample (excluding 'read'), check if both read=1 and read=2 exist\n",
    "group_cols = [col for col in parsed_df.columns if col != \"read\"]\n",
    "read_counts = parsed_df.groupby(group_cols)[\"read\"].nunique().reset_index()\n",
    "# Entries where the number of unique reads is not 2 (i.e., missing a read)\n",
    "missing_reads = read_counts[read_counts[\"read\"] != 2]\n",
    "if not missing_reads.empty:\n",
    "    print(\"Entries missing either read=1 or read=2:\")\n",
    "    display(missing_reads)\n",
    "else:\n",
    "    print(\"All entries have both read=1 and read=2.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop read 2\n",
    "# Merge parsed_df back to df to keep all columns\n",
    "merged_df_validation = pd.concat([df.reset_index(drop=True), parsed_df.reset_index(drop=True)], axis=1)\n",
    "\n",
    "# Identify columns to compare for \"exact same value\" (excluding 'read')\n",
    "compare_cols = [col for col in parsed_df.columns if col != \"read\"]\n",
    "\n",
    "# Sort so that read=1 comes before read=2 for duplicates\n",
    "merged_df_sorted = merged_df_validation.sort_values(by=compare_cols + [\"read\"])\n",
    "\n",
    "# Drop duplicates, keeping the first (which will be read=1 if both exist)\n",
    "dedup_df = merged_df_sorted.drop_duplicates(subset=compare_cols, keep=\"first\")\n",
    "\n",
    "new_df = dedup_df[parsed_df.columns].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get metadata to compare\n",
    "# Group merged_df by \"age\", \"sex\", and \"genotype\" and count the number of rows in each group\n",
    "grouped = new_df.groupby([\"age\", \"sex\", \"genotype\"]).size().reset_index(name='count')\n",
    "\n",
    "print(\"\\n=== GROUPED COUNTS BY age, sex, genotype ===\")\n",
    "print(grouped)\n",
    "\n",
    "print(f\"\\nNumber of unique groups: {grouped.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore what the differences are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = new_df[(new_df[\"sex\"] == \"F\") & (new_df[\"age\"] == \"12mo\") & (new_df[\"genotype\"] == \"5xFADHEMI_CLU-h2kbKI_HO\")]\n",
    "print(\"Rows with sex=F, age=12mo, genotype=5xFADHEMI_CLU-h2kbKI_HO:\")\n",
    "print(filtered_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Rows where ageDeath=12mo, sex=female, and genotype=5XFAD_carrier, Clu-rs2279590_KI_homozygous:\n",
      "     individualID specimenID specimenIdSource  organ           tissue  \\\n",
      "37        12682.0    12682lh          UCI_TMF  brain      hippocampus   \n",
      "38        12682.0    12682lc          UCI_TMF  brain  cerebral cortex   \n",
      "39        12683.0    12683lh          UCI_TMF  brain      hippocampus   \n",
      "40        12683.0    12683lc          UCI_TMF  brain  cerebral cortex   \n",
      "41        12688.0    12688lh          UCI_TMF  brain      hippocampus   \n",
      "42        12688.0    12688lc          UCI_TMF  brain  cerebral cortex   \n",
      "43        12689.0    12689lh          UCI_TMF  brain      hippocampus   \n",
      "44        12689.0    12689lc          UCI_TMF  brain  cerebral cortex   \n",
      "112       12680.0    12680lc          UCI_TMF  brain  cerebral cortex   \n",
      "\n",
      "     BrodmannArea sampleStatus  tissueWeight  tissueVolume nucleicAcidSource  \\\n",
      "37            NaN       frozen           NaN           NaN         bulk cell   \n",
      "38            NaN       frozen           NaN           NaN         bulk cell   \n",
      "39            NaN       frozen           NaN           NaN         bulk cell   \n",
      "40            NaN       frozen           NaN           NaN         bulk cell   \n",
      "41            NaN       frozen           NaN           NaN         bulk cell   \n",
      "42            NaN       frozen           NaN           NaN         bulk cell   \n",
      "43            NaN       frozen           NaN           NaN         bulk cell   \n",
      "44            NaN       frozen           NaN           NaN         bulk cell   \n",
      "112           NaN       frozen           NaN           NaN         bulk cell   \n",
      "\n",
      "     ...       readLength    runType totalReads  validBarcodeReads DV200  \\\n",
      "37   ...  R1:150 ; R2:150  pairedEnd        NaN                NaN   NaN   \n",
      "38   ...  R1:150 ; R2:150  pairedEnd        NaN                NaN   NaN   \n",
      "39   ...  R1:150 ; R2:150  pairedEnd        NaN                NaN   NaN   \n",
      "40   ...  R1:150 ; R2:150  pairedEnd        NaN                NaN   NaN   \n",
      "41   ...  R1:150 ; R2:150  pairedEnd        NaN                NaN   NaN   \n",
      "42   ...  R1:150 ; R2:150  pairedEnd        NaN                NaN   NaN   \n",
      "43   ...  R1:150 ; R2:150  pairedEnd        NaN                NaN   NaN   \n",
      "44   ...  R1:150 ; R2:150  pairedEnd        NaN                NaN   NaN   \n",
      "112  ...  R1:150 ; R2:150  pairedEnd        NaN                NaN   NaN   \n",
      "\n",
      "     inputTotalRNA ribosomalDepletion  globinRemoval  Unnamed: 23 Unnamed: 24  \n",
      "37             NaN                NaN            NaN          NaN         NaN  \n",
      "38             NaN                NaN            NaN          NaN         NaN  \n",
      "39             NaN                NaN            NaN          NaN         NaN  \n",
      "40             NaN                NaN            NaN          NaN         NaN  \n",
      "41             NaN                NaN            NaN          NaN         NaN  \n",
      "42             NaN                NaN            NaN          NaN         NaN  \n",
      "43             NaN                NaN            NaN          NaN         NaN  \n",
      "44             NaN                NaN            NaN          NaN         NaN  \n",
      "112            NaN                NaN            NaN          NaN         NaN  \n",
      "\n",
      "[9 rows x 67 columns]\n"
     ]
    }
   ],
   "source": [
    "# Filter merged_df for the specified criteria\n",
    "filtered_df = merged_df[\n",
    "    (merged_df[\"ageDeath\"] == 12.0) &\n",
    "    (merged_df[\"sex\"] == \"female\") &\n",
    "    (merged_df[\"genotype\"] == \"5XFAD_carrier, Clu-rs2279590_KI_homozygous\")\n",
    "]\n",
    "\n",
    "print(\"\\nRows where ageDeath=12mo, sex=female, and genotype=5XFAD_carrier, Clu-rs2279590_KI_homozygous:\")\n",
    "print(filtered_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adt_py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
