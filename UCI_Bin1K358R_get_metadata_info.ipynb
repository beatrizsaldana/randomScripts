{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Information from Metadata\n",
    "https://www.synapse.org/Synapse:syn50944327"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== BIOSPECIMEN DATAFRAME ===\n",
      "Shape: 653 rows x 17 columns\n",
      "Columns: ['individualID', 'specimenID', 'specimenIdSource', 'organ', 'tissue', 'BrodmannArea', 'sampleStatus', 'tissueWeight', 'tissueVolume', 'nucleicAcidSource', 'cellType', 'fastingState', 'isPostMortem', 'samplingAge', 'samplingAgeUnits', 'visitNumber', 'assay']\n",
      "Number of unique individualIDs: 112\n",
      "Number of rows with missing individualID: 0\n",
      "Number of unique specimenIDs: 499\n",
      "Number of rows with missing specimenIDs: 0\n",
      "\n",
      "=== INDIVIDUAL DATAFRAME ===\n",
      "Shape: 112 rows x 27 columns\n",
      "Columns: ['individualID', 'climbID', 'microchipID', 'birthID', 'matingID', 'individualIdSource', 'materialOrigin', 'sex', 'species', 'generation', 'dateBirth', 'ageDeath', 'ageDeathUnits', 'brainWeight', 'rodentWeight', 'rodentDiet', 'bedding', 'room', 'waterpH', 'treatmentDose', 'treatmentType', 'stockNumber', 'genotype', 'genotypeBackground', 'individualCommonGenotype', 'modelSystemName', 'officialName']\n",
      "Number of unique individualIDs: 112\n",
      "Number of rows with missing individualID: 0\n",
      "'specimenID' column not found.\n",
      "\n",
      "=== RNASEQMETADATA DATAFRAME ===\n",
      "Shape: 74 rows x 36 columns\n",
      "Columns: ['specimenID', 'libraryID', 'assay', 'platform', 'RIN', 'referenceSet', 'rnaBatch', 'libraryBatch', 'sequencingBatch', 'libraryPrep', 'libraryPreparationMethod', 'libraryVersion', 'isStranded', 'readStrandOrigin', 'readLength', 'runType', 'totalReads', 'validBarcodeReads', 'DV200', 'Unnamed: 19', 'Unnamed: 20', 'Unnamed: 21', 'Unnamed: 22', 'Unnamed: 23', 'Unnamed: 24', 'Unnamed: 25', 'Unnamed: 26', 'Unnamed: 27', 'Unnamed: 28', 'Unnamed: 29', 'Unnamed: 30', 'Unnamed: 31', 'Unnamed: 32', 'Unnamed: 33', 'Unnamed: 34', 'Unnamed: 35']\n",
      "'individualID' column not found.\n",
      "Number of unique specimenIDs: 74\n",
      "Number of rows with missing specimenIDs: 0\n"
     ]
    }
   ],
   "source": [
    "# Read in the data\n",
    "biospecimen = pd.read_csv(\"UCI_BIN1_biospecimen_metadata.csv\") #syn51747924\n",
    "individual = pd.read_csv(\"UCI_BIN1_individualID_metadata.csv\") #syn51747927\n",
    "assay_metadata = pd.read_csv(\"UCI_BIN1_RNAseq_assay_template.csv\") #syn51747930\n",
    "\n",
    "# Drop empty rows (all-NaN) for each dataframe\n",
    "biospecimen = biospecimen.dropna(how='all')\n",
    "individual = individual.dropna(how='all')\n",
    "assay_metadata = assay_metadata.dropna(how='all')\n",
    "\n",
    "\n",
    "# Print basic info for each dataframe\n",
    "for name, df in [(\"biospecimen\", biospecimen), (\"individual\", individual), (\"assay_metadata\", assay_metadata)]:\n",
    "    print(f\"\\n=== {name.upper()} DATAFRAME ===\")\n",
    "    print(f\"Shape: {df.shape[0]} rows x {df.shape[1]} columns\")\n",
    "    print(f\"Columns: {list(df.columns)}\")\n",
    "    if 'individualID' in df.columns:\n",
    "        print(f\"Number of unique individualIDs: {df['individualID'].nunique()}\")\n",
    "        print(f\"Number of rows with missing individualID: {df['individualID'].isna().sum()}\")\n",
    "    else:\n",
    "        print(\"'individualID' column not found.\")\n",
    "    if 'specimenID' in df.columns:\n",
    "        print(f\"Number of unique specimenIDs: {df['specimenID'].nunique()}\")\n",
    "        print(f\"Number of rows with missing specimenIDs: {df['specimenID'].isna().sum()}\")\n",
    "    else:\n",
    "        print(\"'specimenID' column not found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== MERGED DATAFRAME INFO ===\n",
      "Shape: 74 rows x 78 columns\n",
      "Columns: ['individualID', 'specimenID', 'specimenIdSource', 'organ', 'tissue', 'BrodmannArea', 'sampleStatus', 'tissueWeight', 'tissueVolume', 'nucleicAcidSource', 'cellType', 'fastingState', 'isPostMortem', 'samplingAge', 'samplingAgeUnits', 'visitNumber', 'assay_x', 'climbID', 'microchipID', 'birthID', 'matingID', 'individualIdSource', 'materialOrigin', 'sex', 'species', 'generation', 'dateBirth', 'ageDeath', 'ageDeathUnits', 'brainWeight', 'rodentWeight', 'rodentDiet', 'bedding', 'room', 'waterpH', 'treatmentDose', 'treatmentType', 'stockNumber', 'genotype', 'genotypeBackground', 'individualCommonGenotype', 'modelSystemName', 'officialName', 'libraryID', 'assay_y', 'platform', 'RIN', 'referenceSet', 'rnaBatch', 'libraryBatch', 'sequencingBatch', 'libraryPrep', 'libraryPreparationMethod', 'libraryVersion', 'isStranded', 'readStrandOrigin', 'readLength', 'runType', 'totalReads', 'validBarcodeReads', 'DV200', 'Unnamed: 19', 'Unnamed: 20', 'Unnamed: 21', 'Unnamed: 22', 'Unnamed: 23', 'Unnamed: 24', 'Unnamed: 25', 'Unnamed: 26', 'Unnamed: 27', 'Unnamed: 28', 'Unnamed: 29', 'Unnamed: 30', 'Unnamed: 31', 'Unnamed: 32', 'Unnamed: 33', 'Unnamed: 34', 'Unnamed: 35']\n",
      "Number of unique individualIDs: 74\n",
      "Number of rows with missing individualID: 0\n",
      "Number of unique specimenIDs: 74\n",
      "Number of rows with missing specimenID: 0\n",
      "\n",
      "First 5 rows of merged_df:\n",
      "   individualID specimenID specimenIdSource  organ       tissue  BrodmannArea  \\\n",
      "0         13048    13048lh          UCI_TMF  brain  hippocampus           NaN   \n",
      "1         13022    13022lh          UCI_TMF  brain  hippocampus           NaN   \n",
      "2         13020    13020lh          UCI_TMF  brain  hippocampus           NaN   \n",
      "3         13046    13046lh          UCI_TMF  brain  hippocampus           NaN   \n",
      "4         13044    13044lh          UCI_TMF  brain  hippocampus           NaN   \n",
      "\n",
      "  sampleStatus  tissueWeight  tissueVolume nucleicAcidSource  ...  \\\n",
      "0       frozen           NaN           NaN         bulk cell  ...   \n",
      "1       frozen           NaN           NaN         bulk cell  ...   \n",
      "2       frozen           NaN           NaN         bulk cell  ...   \n",
      "3       frozen           NaN           NaN         bulk cell  ...   \n",
      "4       frozen           NaN           NaN         bulk cell  ...   \n",
      "\n",
      "   Unnamed: 26  Unnamed: 27  Unnamed: 28  Unnamed: 29 Unnamed: 30  \\\n",
      "0          NaN          NaN          NaN          NaN         NaN   \n",
      "1          NaN          NaN          NaN          NaN         NaN   \n",
      "2          NaN          NaN          NaN          NaN         NaN   \n",
      "3          NaN          NaN          NaN          NaN         NaN   \n",
      "4          NaN          NaN          NaN          NaN         NaN   \n",
      "\n",
      "   Unnamed: 31 Unnamed: 32  Unnamed: 33  Unnamed: 34 Unnamed: 35  \n",
      "0          NaN         NaN          NaN          NaN         NaN  \n",
      "1          NaN         NaN          NaN          NaN         NaN  \n",
      "2          NaN         NaN          NaN          NaN         NaN  \n",
      "3          NaN         NaN          NaN          NaN         NaN  \n",
      "4          NaN         NaN          NaN          NaN         NaN  \n",
      "\n",
      "[5 rows x 78 columns]\n"
     ]
    }
   ],
   "source": [
    "# Merge the dataframes\n",
    "merged1_df = pd.merge(biospecimen, individual, on='individualID', how='outer')\n",
    "merged_df = pd.merge(merged1_df, assay_metadata, on='specimenID', how='inner')\n",
    "\n",
    "print(\"\\n=== MERGED DATAFRAME INFO ===\")\n",
    "print(f\"Shape: {merged_df.shape[0]} rows x {merged_df.shape[1]} columns\")\n",
    "print(f\"Columns: {list(merged_df.columns)}\")\n",
    "\n",
    "if 'individualID' in merged_df.columns:\n",
    "    print(f\"Number of unique individualIDs: {merged_df['individualID'].nunique()}\")\n",
    "    print(f\"Number of rows with missing individualID: {merged_df['individualID'].isna().sum()}\")\n",
    "else:\n",
    "    print(\"'individualID' column not found in merged_df.\")\n",
    "\n",
    "if 'specimenID' in merged_df.columns:\n",
    "    print(f\"Number of unique specimenIDs: {merged_df['specimenID'].nunique()}\")\n",
    "    print(f\"Number of rows with missing specimenID: {merged_df['specimenID'].isna().sum()}\")\n",
    "else:\n",
    "    print(\"'specimenID' column not found in merged_df.\")\n",
    "\n",
    "print(\"\\nFirst 5 rows of merged_df:\")\n",
    "print(merged_df.head())\n",
    "\n",
    "print(f\"Total number of unique specimenIDs in merged_df: {merged_df['specimenID'].nunique()}\")\n",
    "specimenid_counts = merged_df['specimenID'].value_counts(dropna=False)\n",
    "num_singleton_specimenids = (specimenid_counts == 1).sum()\n",
    "print(f\"Number of specimenIDs that only appear once in merged_df: {num_singleton_specimenids}\")\n",
    "\n",
    "num_multi_specimenids = (specimenid_counts > 1).sum()\n",
    "print(f\"Number of specimenIDs that appear more than once in merged_df: {num_multi_specimenids}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unique entries in 'tissue' column:\n",
      "- hippocampus\n",
      "\n",
      "Total unique tissues: 1\n",
      "\n",
      "Unique entries in 'genotype' column:\n",
      "- 5XFAD_carrier, BIN1-K358R_homozygous\n",
      "- 5XFAD_carrier\n",
      "- BIN1-K358R_homozygous\n",
      "- 5XFAD_noncarrier\n",
      "\n",
      "Total unique genotypes: 4\n",
      "\n",
      "Number of entries for each tissue for each genotype:\n",
      "- 5XFAD_carrier:\n",
      "    - hippocampus: 19\n",
      "- 5XFAD_carrier, BIN1-K358R_homozygous:\n",
      "    - hippocampus: 19\n",
      "- 5XFAD_noncarrier:\n",
      "    - hippocampus: 17\n",
      "- BIN1-K358R_homozygous:\n",
      "    - hippocampus: 19\n",
      "\n",
      "Number of unique (specimenID, individualID) pairs: 74\n"
     ]
    }
   ],
   "source": [
    "# Just looking at some stuff, not neccessary to run\n",
    "# Print unique entries for the \"tissue\" column in merged_df\n",
    "if \"tissue\" in merged_df.columns:\n",
    "    unique_tissues = merged_df[\"tissue\"].dropna().unique()\n",
    "    print(\"\\nUnique entries in 'tissue' column:\")\n",
    "    for t in unique_tissues:\n",
    "        print(f\"- {t}\")\n",
    "    print(f\"\\nTotal unique tissues: {len(unique_tissues)}\")\n",
    "else:\n",
    "    print(\"'tissue' column not found in merged_df.\")\n",
    "\n",
    "# Print unique entries for the \"genotype\" column in merged_df\n",
    "if \"genotype\" in merged_df.columns:\n",
    "    unique_genotypes = merged_df[\"genotype\"].dropna().unique()\n",
    "    print(\"\\nUnique entries in 'genotype' column:\")\n",
    "    for g in unique_genotypes:\n",
    "        print(f\"- {g}\")\n",
    "    print(f\"\\nTotal unique genotypes: {len(unique_genotypes)}\")\n",
    "else:\n",
    "    print(\"'genotype' column not found in merged_df.\")\n",
    "\n",
    "# Print the number of entries for each tissue for each genotype\n",
    "if \"genotype\" in merged_df.columns and \"tissue\" in merged_df.columns:\n",
    "    counts = merged_df.groupby([\"genotype\", \"tissue\"]).size().reset_index(name=\"count\")\n",
    "    print(\"\\nNumber of entries for each tissue for each genotype:\")\n",
    "    if counts.empty:\n",
    "        print(\"No data found for genotype and tissue combinations.\")\n",
    "    else:\n",
    "        for g in counts[\"genotype\"].unique():\n",
    "            print(f\"- {g}:\")\n",
    "            sub = counts[counts[\"genotype\"] == g]\n",
    "            for _, row in sub.iterrows():\n",
    "                print(f\"    - {row['tissue']}: {row['count']}\")\n",
    "else:\n",
    "    print(\"Either 'genotype' or 'tissue' column not found in merged_df.\")\n",
    "\n",
    "# Print the number of unique (specimenID, individualID) pairs in merged_df\n",
    "if 'specimenID' in merged_df.columns and 'individualID' in merged_df.columns:\n",
    "    unique_pairs = merged_df[['specimenID', 'individualID']].drop_duplicates()\n",
    "    print(f\"\\nNumber of unique (specimenID, individualID) pairs: {len(unique_pairs)}\")\n",
    "else:\n",
    "    print(\"Either 'specimenID' or 'individualID' column not found in merged_df.\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== GROUPED COUNTS BY ageDeath, sex, genotype ===\n",
      "    ageDeath     sex                              genotype  count\n",
      "0          4  female                         5XFAD_carrier      5\n",
      "1          4  female  5XFAD_carrier, BIN1-K358R_homozygous      4\n",
      "2          4  female                      5XFAD_noncarrier      2\n",
      "3          4  female                 BIN1-K358R_homozygous      4\n",
      "4          4    male                         5XFAD_carrier      5\n",
      "5          4    male  5XFAD_carrier, BIN1-K358R_homozygous      5\n",
      "6          4    male                      5XFAD_noncarrier      5\n",
      "7          4    male                 BIN1-K358R_homozygous      5\n",
      "8         12  female                         5XFAD_carrier      5\n",
      "9         12  female  5XFAD_carrier, BIN1-K358R_homozygous      5\n",
      "10        12  female                      5XFAD_noncarrier      5\n",
      "11        12  female                 BIN1-K358R_homozygous      5\n",
      "12        12    male                         5XFAD_carrier      4\n",
      "13        12    male  5XFAD_carrier, BIN1-K358R_homozygous      5\n",
      "14        12    male                      5XFAD_noncarrier      5\n",
      "15        12    male                 BIN1-K358R_homozygous      5\n",
      "\n",
      "Number of unique groups: 16\n"
     ]
    }
   ],
   "source": [
    "# GET THE DATA FOR THE SPREADSHEET (https://docs.google.com/spreadsheets/d/11vmntFrno9ubNMOE8bbMejEROPygmeJZ/edit?pli=1&gid=757405125#gid=757405125)\n",
    "# Group merged_df by \"ageDeath\", \"sex\", and \"genotype\" and count the number of rows in each group\n",
    "grouped = merged_df.groupby([\"ageDeath\", \"sex\", \"genotype\"]).size().reset_index(name='count')\n",
    "\n",
    "print(\"\\n=== GROUPED COUNTS BY ageDeath, sex, genotype ===\")\n",
    "print(grouped)\n",
    "\n",
    "print(f\"\\nNumber of unique groups: {grouped.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== IndividualIDs for each (ageDeath, sex, genotype) group ===\n",
      "- ageDeath: 4, sex: female, genotype: 5XFAD_carrier\n",
      "  individualIDs (5): 11626, 11625, 11617, 11616, 11615\n",
      "  specimenIDs (30): 11626p, 11626lcif, 11626lhif, 11626lhsf, Pool-E, Pool-U, 11626lh, 11625p, 11625lcif, 11625lhif, 11625lcsf, 11625lhsf, 11625lh, 11617p, 11617lcif, 11617lhif, 11617lhsf, 11617lh, 11616p, 11616lcif, 11616lhif, 11616lcsf, 11616lhsf, 11616lh, 11615p, 11615lcif, 11615lhif, 11615lcsf, 11615lhsf, 11615lh\n",
      "- ageDeath: 4, sex: female, genotype: 5XFAD_carrier, BIN1-K358R_homozygous\n",
      "  individualIDs (7): 13053, 13052, 13048, 13022, 13020, 13019, 13143\n",
      "  specimenIDs (30): 13053p, 13053lcif, 13053lhif, 13053lcsf, 13053lhsf, Pool-G, Pool-W, 13052p, 13052lhsf, 13048p, 13048lcif, 13048lhif, 13048lcsf, 13048lhsf, 13048lh, 13022p, 13022lcif, 13022lhif, 13022lcsf, 13022lhsf, 13022lh, 13020p, 13020lcif, 13020lhif, 13020lcsf, 13020lhsf, 13020lh, 13019lcif, 13019lhif, 13019lh\n",
      "- ageDeath: 4, sex: female, genotype: 5XFAD_noncarrier\n",
      "  individualIDs (4): 11629, 11628, 11627, 11618\n",
      "  specimenIDs (8): 11629p, Pool-A, Pool-Q, 11629lh, 11628p, 11627p, 11627lh, 11618p\n",
      "- ageDeath: 4, sex: female, genotype: BIN1-K358R_homozygous\n",
      "  individualIDs (6): 13051, 13050, 13049, 13047, 13039, 13036\n",
      "  specimenIDs (11): 13051p, Pool-C, Pool-S, 13050p, 13049p, 13049lh, 13047p, 13047lh, 13039p, 13039lh, 13036lh\n",
      "- ageDeath: 4, sex: male, genotype: 5XFAD_carrier\n",
      "  individualIDs (6): 11633, 11631, 11622, 11621, 11619, 11611\n",
      "  specimenIDs (32): 11633p, 11633lcsf, 11633lhsf, Pool-F, Pool-V, 11631p, 11631lcif, 11631lhif, 11631lcsf, 11631lhsf, 11631lh, 11622p, 11622lcif, 11622lhif, 11622lcsf, 11622lhsf, 11622lh, 11621p, 11621lcif, 11621lhif, 11621lcsf, 11621lhsf, 11621lh, 11619p, 11619lcif, 11619lhif, 11619lcsf, 11619lhsf, 11619lh, 11611lcif, 11611lhif, 11611lh\n",
      "- ageDeath: 4, sex: male, genotype: 5XFAD_carrier, BIN1-K358R_homozygous\n",
      "  individualIDs (6): 13046, 13044, 13043, 13040, 13034, 13028\n",
      "  specimenIDs (32): 13046p, 13046lcif, 13046lhif, 13046lcsf, 13046lhsf, Pool-H, Pool-X, 13046lh, 13044p, 13044lcsf, 13044lhsf, 13044lh, 13043p, 13043lcif, 13043lhif, 13043lcsf, 13043lhsf, 13040p, 13040lcif, 13040lhif, 13040lcsf, 13040lhsf, 13040lh, 13034p, 13034lcif, 13034lhif, 13034lcsf, 13034lhsf, 13034lh, 13028lcif, 13028lhif, 13028lh\n",
      "- ageDeath: 4, sex: male, genotype: 5XFAD_noncarrier\n",
      "  individualIDs (6): 11636, 11632, 11624, 11623, 11614, 11620\n",
      "  specimenIDs (12): 11636p, Pool-B, Pool-R, 11636lh, 11632p, 11624p, 11624lh, 11623p, 11623lh, 11614p, 11614lh, 11620lh\n",
      "- ageDeath: 4, sex: male, genotype: BIN1-K358R_homozygous\n",
      "  individualIDs (6): 13045, 13042, 13041, 13037, 13027, 13024\n",
      "  specimenIDs (12): 13045p, Pool-D, Pool-T, 13045lh, 13042p, 13041p, 13041lh, 13037p, 13037lh, 13027p, 13027lh, 13024lh\n",
      "- ageDeath: 12, sex: female, genotype: 5XFAD_carrier\n",
      "  individualIDs (6): 12452, 12450, 12443, 12440, 12433, 12431\n",
      "  specimenIDs (39): 12452p, 12452lcif, 12452lhif, 12452lcsf, 12452lhsf, Pool-M, Pool-AC, 12452lh, 12450p, 12450lcif, 12450lhif, 12450lcsf, 12450lhsf, 12450lh, 12443p, 12443lcif, 12443lhif, 12443lcsf, 12443lhsf, 12443lh, 12440p, 12440lcif, 12440lhif, 12440lcsf, 12440lhsf, 12440lh, 12440lc, 12433p, 12433lcif, 12433lhif, 12433lcsf, 12433lhsf, 12433lh, 12433lc, 12431p, 12431lcif, 12431lhif, 12431lcsf, 12431lhsf\n",
      "- ageDeath: 12, sex: female, genotype: 5XFAD_carrier, BIN1-K358R_homozygous\n",
      "  individualIDs (6): 13035, 13031, 12981, 12841, 12839, 12576\n",
      "  specimenIDs (39): 13035p, 13035lcif, 13035lhif, 13035lcsf, 13035lhsf, Pool-O, Pool-AE, 13035lh, 13035lc, 13031p, 13031lcif, 13031lhif, 13031lcsf, 13031lhsf, 12981p, 12981lcif, 12981lhif, 12981lcsf, 12981lhsf, 12981lh, 12981lc, 12841p, 12841lcif, 12841lhif, 12841lcsf, 12841lhsf, 12841lh, 12839p, 12839lcif, 12839lhif, 12839lcsf, 12839lhsf, 12839lh, 12576p, 12576lcif, 12576lhif, 12576lcsf, 12576lhsf, 12576lh\n",
      "- ageDeath: 12, sex: female, genotype: 5XFAD_noncarrier\n",
      "  individualIDs (6): 12487, 12442, 12441, 12432, 12426, 12417\n",
      "  specimenIDs (39): 12487p, 12487lhif, 12487lhsf, 12487lcif, 12487lcsf, Pool-I, Pool-Y, 12487lh, 12442p, 12442lhif, 12442lhsf, 12442lcif, 12442lcsf, 12442lh, 12441p, 12441lhif, 12441lhsf, 12441lcif, 12441lcsf, 12441lh, 12432p, 12432lhif, 12432lhsf, 12432lcif, 12432lcsf, 12432lh, 12432lc, 12426p, 12426lhif, 12426lhsf, 12426lcif, 12426lcsf, 12426lh, 12426lc, 12417p, 12417lhif, 12417lhsf, 12417lcif, 12417lcsf\n",
      "- ageDeath: 12, sex: female, genotype: AppAbeta_LoxP_noncarrier\n",
      "  individualIDs (6): 17752, 17751, 17749, 17854, 18001, 18000\n",
      "  specimenIDs (12): 17752lh, 17752rh, 17751lh, 17751rh, 17749lh, 17749rh, 17854lh, 17854rh, 18001lh, 18001rh, 18000lh, 18000rh\n",
      "- ageDeath: 12, sex: female, genotype: BIN1-K358R_homozygous\n",
      "  individualIDs (8): 13021, 13016, 13029, 13030, 13032, 13033, 18104, 18103\n",
      "  specimenIDs (43): 13021p, 13021lhif, 13021lhsf, 13021lcif, 13021lcsf, Pool-K, Pool-AA, 13021lh, 13021lc, 13016p, 13016lhif, 13016lhsf, 13016lcif, 13016lcsf, 13016lc, 13029p, 13029lhif, 13029lhsf, 13029lcif, 13029lcsf, 13029lh, 13030p, 13030lhif, 13030lhsf, 13030lcif, 13030lcsf, 13030lh, 13032p, 13032lhif, 13032lhsf, 13032lcif, 13032lcsf, 13032lh, 13033p, 13033lhif, 13033lhsf, 13033lcif, 13033lcsf, 13033lh, 18104lh, 18104rh, 18103lh, 18103rh\n",
      "- ageDeath: 12, sex: male, genotype: 5XFAD_carrier\n",
      "  individualIDs (6): 12424, 12423, 12422, 12420, 12802, 12801\n",
      "  specimenIDs (31): 12424p, 12424lcif, 12424lhif, 12424lcsf, 12424lhsf, Pool-N, Pool-AD, 12424lh, 12423p, 12423lcif, 12423lhif, 12423lcsf, 12423lhsf, 12422p, 12422lcif, 12422lhif, 12422lcsf, 12422lhsf, 12422lh, 12420p, 12420lcif, 12420lhif, 12420lcsf, 12420lhsf, 12420lh, 12802p, 12802lcif, 12802lhif, 12802lcsf, 12802lhsf, 12802lh\n",
      "- ageDeath: 12, sex: male, genotype: 5XFAD_carrier, BIN1-K358R_homozygous\n",
      "  individualIDs (6): 12977, 12978, 12979, 12980, 13025, 13026\n",
      "  specimenIDs (35): 12977p, 12977lcif, 12977lhif, 12977lcsf, 12977lhsf, Pool-P, Pool-AF, 12977lh, 12978p, 12978lcif, 12978lhif, 12978lcsf, 12978lhsf, 12979p, 12979lcif, 12979lhif, 12979lcsf, 12979lhsf, 12979lh, 12980p, 12980lcif, 12980lhif, 12980lcsf, 12980lhsf, 12980lh, 13025p, 13025lcif, 13025lhif, 13025lcsf, 13025lhsf, 13025lh, 13026p, 13026lcif, 13026lcsf, 13026lh\n",
      "- ageDeath: 12, sex: male, genotype: 5XFAD_noncarrier\n",
      "  individualIDs (6): 12435, 12434, 12429, 12421, 12419, 12915\n",
      "  specimenIDs (37): 12435p, 12435lhif, 12435lhsf, 12435lcif, 12435lcsf, Pool-J, Pool-Z, 12435lh, 12434p, 12434lhif, 12434lhsf, 12434lcif, 12434lcsf, 12434lh, 12429p, 12429lhif, 12429lhsf, 12429lcif, 12429lcsf, 12429lh, 12421p, 12421lhif, 12421lhsf, 12421lcif, 12421lcsf, 12421lh, 12419p, 12419lhif, 12419lhsf, 12419lcif, 12419lcsf, 12419lh, 12915p, 12915lhif, 12915lhsf, 12915lcif, 12915lcsf\n",
      "- ageDeath: 12, sex: male, genotype: AppAbeta_LoxP_noncarrier\n",
      "  individualIDs (5): 17850, 17852, 17853, 17851, 17882\n",
      "  specimenIDs (10): 17850lh, 17850rh, 17852lh, 17852rh, 17853lh, 17853rh, 17851lh, 17851rh, 17882lh, 17882rh\n",
      "- ageDeath: 12, sex: male, genotype: BIN1-K358R_homozygous\n",
      "  individualIDs (11): 13012, 13013, 13017, 13018, 12976, 13023, 18102, 18100, 18101, 18099, 18098\n",
      "  specimenIDs (47): 13012p, 13012lhif, 13012lhsf, 13012lcif, 13012lcsf, Pool-L, Pool-AB, 13012lh, 13013p, 13013lhif, 13013lhsf, 13013lcif, 13013lcsf, 13013lh, 13017p, 13017lhif, 13017lhsf, 13017lcif, 13017lcsf, 13017lh, 13018p, 13018lhif, 13018lhsf, 13018lcif, 13018lcsf, 13018lh, 12976p, 12976lhif, 12976lhsf, 12976lcif, 12976lcsf, 12976lh, 13023p, 13023lhif, 13023lhsf, 13023lcif, 13023lcsf, 18102lh, 18102rh, 18100lh, 18100rh, 18101lh, 18101rh, 18099lh, 18099rh, 18098lh, 18098rh\n",
      "\n",
      "All individualIDs from all groups (unique):\n",
      "[11626, 11625, 11617, 11616, 11615, 13053, 13052, 13048, 13022, 13020, 13019, 13143, 11629, 11628, 11627, 11618, 13051, 13050, 13049, 13047, 13039, 13036, 11633, 11631, 11622, 11621, 11619, 11611, 13046, 13044, 13043, 13040, 13034, 13028, 11636, 11632, 11624, 11623, 11614, 11620, 13045, 13042, 13041, 13037, 13027, 13024, 12452, 12450, 12443, 12440, 12433, 12431, 13035, 13031, 12981, 12841, 12839, 12576, 12487, 12442, 12441, 12432, 12426, 12417, 17752, 17751, 17749, 17854, 18001, 18000, 13021, 13016, 13029, 13030, 13032, 13033, 18104, 18103, 12424, 12423, 12422, 12420, 12802, 12801, 12977, 12978, 12979, 12980, 13025, 13026, 12435, 12434, 12429, 12421, 12419, 12915, 17850, 17852, 17853, 17851, 17882, 13012, 13013, 13017, 13018, 12976, 13023, 18102, 18100, 18101, 18099, 18098]\n",
      "\n",
      "Number of unique individualIDs: 112\n"
     ]
    }
   ],
   "source": [
    "# For each group in grouped, get the unique individualIDs from merged_df\n",
    "print(\"\\n=== IndividualIDs and specimenIDs for each (ageDeath, sex, genotype) group ===\")\n",
    "for idx, row in grouped.iterrows():\n",
    "    age = row[\"ageDeath\"]\n",
    "    sex = row[\"sex\"]\n",
    "    genotype = row[\"genotype\"]\n",
    "    # Filter merged_df for this group\n",
    "    mask = (\n",
    "        (merged_df[\"ageDeath\"] == age) &\n",
    "        (merged_df[\"sex\"] == sex) &\n",
    "        (merged_df[\"genotype\"] == genotype)\n",
    "    )\n",
    "    ind_ids = merged_df.loc[mask, \"individualID\"].dropna().unique()\n",
    "    spec_ids = merged_df.loc[mask, \"specimenID\"].dropna().unique()\n",
    "    print(f\"- ageDeath: {age}, sex: {sex}, genotype: {genotype}\")\n",
    "    print(f\"  individualIDs ({len(ind_ids)}): {', '.join(map(str, ind_ids))}\")\n",
    "    print(f\"  specimenIDs ({len(spec_ids)}): {', '.join(map(str, spec_ids))}\")\n",
    "\n",
    "# Collect all unique individualIDs from the groups into a list\n",
    "all_individualIDs = []\n",
    "for idx, row in grouped.iterrows():\n",
    "    age = row[\"ageDeath\"]\n",
    "    sex = row[\"sex\"]\n",
    "    genotype = row[\"genotype\"]\n",
    "    mask = (\n",
    "        (merged_df[\"ageDeath\"] == age) &\n",
    "        (merged_df[\"sex\"] == sex) &\n",
    "        (merged_df[\"genotype\"] == genotype)\n",
    "    )\n",
    "    ids = merged_df.loc[mask, \"individualID\"].dropna().unique()\n",
    "    all_individualIDs.extend(ids)\n",
    "\n",
    "# Remove duplicates while preserving order\n",
    "seen = set()\n",
    "all_individualIDs_unique = []\n",
    "for x in all_individualIDs:\n",
    "    if x not in seen:\n",
    "        all_individualIDs_unique.append(x)\n",
    "        seen.add(x)\n",
    "\n",
    "print(\"\\nAll individualIDs from all groups (unique):\")\n",
    "print(all_individualIDs_unique)\n",
    "print(f\"\\nNumber of unique individualIDs: {len(all_individualIDs_unique)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate Metadata\n",
    "Look at the actual RNAseq data and make sure that all samples exist and align with what is stated in the metadata.\n",
    "https://www.synapse.org/Synapse:syn50944329"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In terminal, run:\n",
    "# synapse list syn50944329 > UCI_Bin1K358R_rnaseqdata_list.csv\n",
    "\n",
    "df = pd.read_csv(\"UCI_Bin1K358R_rnaseqdata_list.csv\", header=None, names=[\"syn_id\", \"file_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    lane tissue sex   genotype   age individualID read\n",
      "0     B1   hipp   F  5XFADHEMI  12mo        12433   R1\n",
      "1     B1   hipp   F  5XFADHEMI  12mo        12433   R2\n",
      "2     B1   hipp   F  5XFADHEMI  12mo        12440   R1\n",
      "3     B1   hipp   F  5XFADHEMI  12mo        12440   R2\n",
      "4     B1   hipp   F  5XFADHEMI  12mo        12450   R1\n",
      "..   ...    ...  ..        ...   ...          ...  ...\n",
      "143   B1   hipp   M    Bin1_HO   4mo        13037   R2\n",
      "144   B1   hipp   M    Bin1_HO   4mo        13041   R1\n",
      "145   B1   hipp   M    Bin1_HO   4mo        13041   R2\n",
      "146   B1   hipp   M    Bin1_HO   4mo        13045   R1\n",
      "147   B1   hipp   M    Bin1_HO   4mo        13045   R2\n",
      "\n",
      "[148 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "# Parse the filename to get the metadata\n",
    "def parse_filename(fname):\n",
    "    # Split by underscore\n",
    "    parts = str(fname).split(\"_\")\n",
    "    # Defensive: if not enough parts, return Nones\n",
    "    if len(parts) < 7:\n",
    "        return {\n",
    "            \"lane\": None,\n",
    "            \"tissue\": None,\n",
    "            \"sex\": None,\n",
    "            \"genotype\": None,\n",
    "            \"age\": None,\n",
    "            \"individualID\": None,\n",
    "            \"read\": None\n",
    "        }\n",
    "    # Find the index of the sex (first \"M\" or \"F\")\n",
    "    try:\n",
    "        sex_idx = next(i for i, p in enumerate(parts) if p in (\"M\", \"F\"))\n",
    "    except StopIteration:\n",
    "        sex_idx = 1  # fallback, but may be wrong\n",
    "    # Find the index of the age (endswith \"mo\")\n",
    "    try:\n",
    "        age_idx = next(i for i, p in enumerate(parts) if p.endswith(\"mo\"))\n",
    "    except StopIteration:\n",
    "        age_idx = sex_idx + 2  # fallback\n",
    "    # Find the index of the individualID (should be after lane)\n",
    "    try:\n",
    "        indiv_idx = age_idx + 2\n",
    "        individualID = parts[indiv_idx]\n",
    "    except IndexError:\n",
    "        individualID = None\n",
    "    # Find the index of the lane (should be after age)\n",
    "    try:\n",
    "        lane_idx = age_idx + 1\n",
    "        lane = parts[lane_idx]\n",
    "    except IndexError:\n",
    "        lane = None\n",
    "    # Read is always the last part before extension, e.g. ..._1.fq.gz or ..._2.fq.gz\n",
    "    read_part = parts[-1]\n",
    "    # If read_part contains a dot, split and take the first part (e.g. \"1.fq.gz\" -> \"1\")\n",
    "    read = read_part.split(\".\")[0]\n",
    "    # Genotype is everything between sex and age\n",
    "    genotype = \"_\".join(parts[sex_idx + 1:age_idx])\n",
    "    return {\n",
    "        \"lane\": lane,\n",
    "        \"tissue\": parts[0],\n",
    "        \"sex\": parts[sex_idx],\n",
    "        \"genotype\": genotype,\n",
    "        \"age\": parts[age_idx],\n",
    "        \"individualID\": individualID,\n",
    "        \"read\": read\n",
    "    }\n",
    "\n",
    "parsed = df[\"file_name\"].apply(parse_filename)\n",
    "parsed_df = pd.DataFrame(parsed.tolist())\n",
    "print(parsed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All entries have both read=1 and read=2.\n"
     ]
    }
   ],
   "source": [
    "# Make sure all samples have both read1 and read2\n",
    "# For each unique sample (excluding 'read'), check if both read=1 and read=2 exist\n",
    "group_cols = [col for col in parsed_df.columns if col != \"read\"]\n",
    "read_counts = parsed_df.groupby(group_cols)[\"read\"].nunique().reset_index()\n",
    "# Entries where the number of unique reads is not 2 (i.e., missing a read)\n",
    "missing_reads = read_counts[read_counts[\"read\"] != 2]\n",
    "if not missing_reads.empty:\n",
    "    print(\"Entries missing either read=1 or read=2:\")\n",
    "    display(missing_reads)\n",
    "else:\n",
    "    print(\"All entries have both read=1 and read=2.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop read 2\n",
    "# Merge parsed_df back to df to keep all columns\n",
    "merged_df_validation = pd.concat([df.reset_index(drop=True), parsed_df.reset_index(drop=True)], axis=1)\n",
    "\n",
    "# Identify columns to compare for \"exact same value\" (excluding 'read')\n",
    "compare_cols = [col for col in parsed_df.columns if col != \"read\"]\n",
    "\n",
    "# Sort so that read=1 comes before read=2 for duplicates\n",
    "merged_df_sorted = merged_df_validation.sort_values(by=compare_cols + [\"read\"])\n",
    "\n",
    "# Drop duplicates, keeping the first (which will be read=1 if both exist)\n",
    "dedup_df = merged_df_sorted.drop_duplicates(subset=compare_cols, keep=\"first\")\n",
    "\n",
    "new_df = dedup_df[parsed_df.columns].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== GROUPED COUNTS BY age, sex, genotype ===\n",
      "     age sex           genotype  count\n",
      "0   12mo   F          5XFADHEMI      5\n",
      "1   12mo   F  5xFADHEMI_Bin1_HO      5\n",
      "2   12mo   F            5xFADWT      5\n",
      "3   12mo   F             BIN1HO      1\n",
      "4   12mo   F            Bin1_HO      4\n",
      "5   12mo   M          5XFADHEMI      4\n",
      "6   12mo   M  5xFADHEMI_Bin1_HO      5\n",
      "7   12mo   M            5xFADWT      5\n",
      "8   12mo   M            Bin1_HO      5\n",
      "9    4mo   F          5xFADHEMI      5\n",
      "10   4mo   F  5xFADHEMI_Bin1_HO      4\n",
      "11   4mo   F            5xFADWT      2\n",
      "12   4mo   F            Bin1_HO      4\n",
      "13   4mo   M          5xFADHEMI      5\n",
      "14   4mo   M  5xFADHEMI_Bin1_HO      5\n",
      "15   4mo   M            5xFADWT      5\n",
      "16   4mo   M            Bin1_HO      5\n",
      "\n",
      "Number of unique groups: 17\n"
     ]
    }
   ],
   "source": [
    "# Get metadata to compare\n",
    "# Group merged_df by \"age\", \"sex\", and \"genotype\" and count the number of rows in each group\n",
    "grouped_validation = new_df.groupby([\"age\", \"sex\", \"genotype\"]).size().reset_index(name='count')\n",
    "\n",
    "print(\"\\n=== GROUPED COUNTS BY age, sex, genotype ===\")\n",
    "print(grouped_validation)\n",
    "\n",
    "print(f\"\\nNumber of unique groups: {grouped_validation.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== individualIDs per group (age, sex, genotype) ===\n",
      "Group (age=12mo, sex=F, genotype=5XFADHEMI):\n",
      "  individualIDs: [12433, 12440, 12450, 12443, 12452]\n",
      "Group (age=12mo, sex=F, genotype=5xFADHEMI_Bin1_HO):\n",
      "  individualIDs: [12576, 12841, 13035, 12839, 12981]\n",
      "Group (age=12mo, sex=F, genotype=5xFADWT):\n",
      "  individualIDs: [12426, 12441, 12442, 12432, 12487]\n",
      "Group (age=12mo, sex=F, genotype=BIN1HO):\n",
      "  individualIDs: [13029]\n",
      "Group (age=12mo, sex=F, genotype=Bin1_HO):\n",
      "  individualIDs: [13021, 13030, 13033, 13032]\n",
      "Group (age=12mo, sex=M, genotype=5XFADHEMI):\n",
      "  individualIDs: [12420, 12424, 12422, 12802]\n",
      "Group (age=12mo, sex=M, genotype=5xFADHEMI_Bin1_HO):\n",
      "  individualIDs: [12977, 12980, 13025, 12979, 13026]\n",
      "Group (age=12mo, sex=M, genotype=5xFADWT):\n",
      "  individualIDs: [12419, 12429, 12434, 12421, 12435]\n",
      "Group (age=12mo, sex=M, genotype=Bin1_HO):\n",
      "  individualIDs: [12976, 13013, 13012, 13017, 13018]\n",
      "Group (age=4mo, sex=F, genotype=5xFADHEMI):\n",
      "  individualIDs: [11615, 11616, 11625, 11626, 11617]\n",
      "Group (age=4mo, sex=F, genotype=5xFADHEMI_Bin1_HO):\n",
      "  individualIDs: [13020, 13019, 13022, 13048]\n",
      "Group (age=4mo, sex=F, genotype=5xFADWT):\n",
      "  individualIDs: [11627, 11629]\n",
      "Group (age=4mo, sex=F, genotype=Bin1_HO):\n",
      "  individualIDs: [13036, 13039, 13047, 13049]\n",
      "Group (age=4mo, sex=M, genotype=5xFADHEMI):\n",
      "  individualIDs: [11611, 11619, 11621, 11622, 11631]\n",
      "Group (age=4mo, sex=M, genotype=5xFADHEMI_Bin1_HO):\n",
      "  individualIDs: [13028, 13034, 13044, 13046, 13040]\n",
      "Group (age=4mo, sex=M, genotype=5xFADWT):\n",
      "  individualIDs: [11614, 11620, 11623, 11624, 11636]\n",
      "Group (age=4mo, sex=M, genotype=Bin1_HO):\n",
      "  individualIDs: [13024, 13027, 13037, 13041, 13045]\n",
      "\n",
      "All individualIDs from all groups:\n",
      "[12433, 12440, 12450, 11615, 11616, 11625, 11626, 12576, 12841, 13035, 13020, 12426, 12441, 12442, 11627, 13021, 13030, 13033, 13036, 13039, 13047, 13049, 12420, 12424, 11611, 11619, 11621, 11622, 11631, 12977, 12980, 13025, 13028, 13034, 13044, 13046, 12419, 12429, 12434, 11614, 11620, 11623, 11624, 11636, 12976, 13013, 13024, 13027, 13037, 13041, 13045, 12443, 12452, 11617, 12839, 12981, 13019, 13022, 13048, 12432, 12487, 11629, 13029, 13032, 12422, 12802, 12979, 13026, 13040, 12421, 12435, 13012, 13017, 13018]\n",
      "\n",
      "Number of unique individualIDs: 74\n",
      "\n",
      "All individualIDs in validation are present in all_individualIDs_unique.\n"
     ]
    }
   ],
   "source": [
    "# For each group in grouped_validation, print the individualIDs in that group\n",
    "print(\"\\n=== individualIDs per group (age, sex, genotype) ===\")\n",
    "for idx, row in grouped_validation.iterrows():\n",
    "    age = row['age']\n",
    "    sex = row['sex']\n",
    "    genotype = row['genotype']\n",
    "    # Filter new_df for this group\n",
    "    group_df = new_df[(new_df['age'] == age) & (new_df['sex'] == sex) & (new_df['genotype'] == genotype)]\n",
    "    individual_ids = group_df['individualID'].unique()\n",
    "    print(f\"Group (age={age}, sex={sex}, genotype={genotype}):\")\n",
    "    print(f\"  individualIDs: {[int(x) for x in list(individual_ids)]}\")\n",
    "\n",
    "# Print all individualIDs from all groups in grouped_validation\n",
    "all_individual_ids_validation = new_df['individualID'].unique()\n",
    "# Ensure all elements of all_individual_ids_validation are ints\n",
    "all_individual_ids_validation = [int(x) for x in all_individual_ids_validation]\n",
    "print(\"\\nAll individualIDs from all groups:\")\n",
    "print(list(all_individual_ids_validation))\n",
    "print(f\"\\nNumber of unique individualIDs: {len(all_individual_ids_validation)}\")\n",
    "\n",
    "\n",
    "\n",
    "# Are there any individualIDs in all_individual_ids_validation that are not in all_individualIDs_unique?\n",
    "# Assuming all_individualIDs_unique is defined elsewhere in the notebook\n",
    "missing_ids = set(all_individual_ids_validation) - set(all_individualIDs_unique)\n",
    "if missing_ids:\n",
    "    print(\"\\nindividualIDs in validation not in all_individualIDs_unique:\")\n",
    "    print(list(missing_ids))\n",
    "else:\n",
    "    print(\"\\nAll individualIDs in validation are present in all_individualIDs_unique.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All individualIDs in unique_specimenIDs_no_lh are present in all_individualIDs_unique.\n"
     ]
    }
   ],
   "source": [
    "# Create a list of all unique specimenIDs from assay_metadata\n",
    "unique_specimenIDs = list(assay_metadata['specimenID'].unique())\n",
    "unique_specimenIDs_no_lh = [int(sid.replace(\"lh\", \"\")) for sid in unique_specimenIDs]\n",
    "\n",
    "# Are there any individualIDs in all_individual_ids_validation that are not in all_individualIDs_unique?\n",
    "missing_ids = set(unique_specimenIDs_no_lh) - set(all_individualIDs_unique)\n",
    "if missing_ids:\n",
    "    print(\"\\nindividualIDs in unique_specimenIDs_no_lh not in all_individualIDs_unique:\")\n",
    "    print(list(missing_ids))\n",
    "else:\n",
    "    print(\"\\nAll individualIDs in unique_specimenIDs_no_lh are present in all_individualIDs_unique.\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adt_py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
