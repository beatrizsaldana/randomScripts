{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Information from Metadata\n",
    "https://www.synapse.org/Synapse:syn50944327"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== BIOSPECIMEN DATAFRAME ===\n",
      "Shape: 653 rows x 17 columns\n",
      "Columns: ['individualID', 'specimenID', 'specimenIdSource', 'organ', 'tissue', 'BrodmannArea', 'sampleStatus', 'tissueWeight', 'tissueVolume', 'nucleicAcidSource', 'cellType', 'fastingState', 'isPostMortem', 'samplingAge', 'samplingAgeUnits', 'visitNumber', 'assay']\n",
      "Number of unique individualIDs: 112\n",
      "Number of rows with missing individualID: 0\n",
      "\n",
      "=== INDIVIDUAL DATAFRAME ===\n",
      "Shape: 112 rows x 27 columns\n",
      "Columns: ['individualID', 'climbID', 'microchipID', 'birthID', 'matingID', 'individualIdSource', 'materialOrigin', 'sex', 'species', 'generation', 'dateBirth', 'ageDeath', 'ageDeathUnits', 'brainWeight', 'rodentWeight', 'rodentDiet', 'bedding', 'room', 'waterpH', 'treatmentDose', 'treatmentType', 'stockNumber', 'genotype', 'genotypeBackground', 'individualCommonGenotype', 'modelSystemName', 'officialName']\n",
      "Number of unique individualIDs: 112\n",
      "Number of rows with missing individualID: 0\n",
      "\n",
      "=== RNASEQMETADATA DATAFRAME ===\n",
      "Shape: 8 rows x 20 columns\n",
      "Columns: ['assay', 'specimenID', 'platform', 'RIN', 'rnaBatch', 'libraryBatch', 'sequencingBatch', 'libraryPrep', 'libraryPreparationMethod', 'libraryType', 'sampleBarcode', 'isStranded', 'readStrandOrigin', 'readLength', 'runType', 'totalReads', 'validBarcodeReads', 'numberCells', 'medianGenes', 'medianUMIs']\n",
      "'individualID' column not found.\n"
     ]
    }
   ],
   "source": [
    "# Read in the data\n",
    "biospecimen = pd.read_csv(\"UCI_BIN1_biospecimen_metadata.csv\")\n",
    "individual = pd.read_csv(\"UCI_BIN1_individualID_metadata.csv\")\n",
    "rnaseqmetadata = pd.read_csv(\"UCI_BIN1_scRNAseq_assay.csv\")\n",
    "\n",
    "# Drop empty rows (all-NaN) for each dataframe\n",
    "biospecimen = biospecimen.dropna(how='all')\n",
    "individual = individual.dropna(how='all')\n",
    "rnaseqmetadata = rnaseqmetadata.dropna(how='all')\n",
    "\n",
    "\n",
    "# Print basic info for each dataframe\n",
    "for name, df in [(\"biospecimen\", biospecimen), (\"individual\", individual), (\"rnaseqmetadata\", rnaseqmetadata)]:\n",
    "    print(f\"\\n=== {name.upper()} DATAFRAME ===\")\n",
    "    print(f\"Shape: {df.shape[0]} rows x {df.shape[1]} columns\")\n",
    "    print(f\"Columns: {list(df.columns)}\")\n",
    "    if 'individualID' in df.columns:\n",
    "        print(f\"Number of unique individualIDs: {df['individualID'].nunique()}\")\n",
    "        print(f\"Number of rows with missing individualID: {df['individualID'].isna().sum()}\")\n",
    "    else:\n",
    "        print(\"'individualID' column not found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== MERGED DATAFRAME INFO ===\n",
      "Shape: 653 rows x 62 columns\n",
      "Columns: ['individualID', 'specimenID', 'specimenIdSource', 'organ', 'tissue', 'BrodmannArea', 'sampleStatus', 'tissueWeight', 'tissueVolume', 'nucleicAcidSource', 'cellType', 'fastingState', 'isPostMortem', 'samplingAge', 'samplingAgeUnits', 'visitNumber', 'assay_x', 'climbID', 'microchipID', 'birthID', 'matingID', 'individualIdSource', 'materialOrigin', 'sex', 'species', 'generation', 'dateBirth', 'ageDeath', 'ageDeathUnits', 'brainWeight', 'rodentWeight', 'rodentDiet', 'bedding', 'room', 'waterpH', 'treatmentDose', 'treatmentType', 'stockNumber', 'genotype', 'genotypeBackground', 'individualCommonGenotype', 'modelSystemName', 'officialName', 'assay_y', 'platform', 'RIN', 'rnaBatch', 'libraryBatch', 'sequencingBatch', 'libraryPrep', 'libraryPreparationMethod', 'libraryType', 'sampleBarcode', 'isStranded', 'readStrandOrigin', 'readLength', 'runType', 'totalReads', 'validBarcodeReads', 'numberCells', 'medianGenes', 'medianUMIs']\n",
      "Number of unique individualIDs: 112\n",
      "Number of rows with missing individualID: 0\n",
      "Number of unique specimenIDs: 499\n",
      "Number of rows with missing specimenID: 0\n",
      "\n",
      "First 5 rows of merged_df:\n",
      "   individualID specimenID specimenIdSource  organ           tissue  \\\n",
      "0         13053     13053p          UCI_TMF  blood           plasma   \n",
      "1         13053  13053lcif          UCI_TMF  brain  cerebral cortex   \n",
      "2         13053  13053lhif          UCI_TMF  brain      hippocampus   \n",
      "3         13053  13053lcsf          UCI_TMF  brain  cerebral cortex   \n",
      "4         13053  13053lhsf          UCI_TMF  brain      hippocampus   \n",
      "\n",
      "   BrodmannArea sampleStatus  tissueWeight  tissueVolume nucleicAcidSource  \\\n",
      "0           NaN          NaN           NaN           NaN               NaN   \n",
      "1           NaN          NaN           NaN           NaN               NaN   \n",
      "2           NaN          NaN           NaN           NaN               NaN   \n",
      "3           NaN          NaN           NaN           NaN               NaN   \n",
      "4           NaN          NaN           NaN           NaN               NaN   \n",
      "\n",
      "   ...  sampleBarcode  isStranded  readStrandOrigin  readLength runType  \\\n",
      "0  ...            NaN         NaN               NaN         NaN     NaN   \n",
      "1  ...            NaN         NaN               NaN         NaN     NaN   \n",
      "2  ...            NaN         NaN               NaN         NaN     NaN   \n",
      "3  ...            NaN         NaN               NaN         NaN     NaN   \n",
      "4  ...            NaN         NaN               NaN         NaN     NaN   \n",
      "\n",
      "   totalReads validBarcodeReads  numberCells  medianGenes medianUMIs  \n",
      "0         NaN               NaN          NaN          NaN        NaN  \n",
      "1         NaN               NaN          NaN          NaN        NaN  \n",
      "2         NaN               NaN          NaN          NaN        NaN  \n",
      "3         NaN               NaN          NaN          NaN        NaN  \n",
      "4         NaN               NaN          NaN          NaN        NaN  \n",
      "\n",
      "[5 rows x 62 columns]\n"
     ]
    }
   ],
   "source": [
    "# Merge the dataframes\n",
    "merged1_df = pd.merge(biospecimen, individual, on='individualID', how='outer')\n",
    "merged_df = pd.merge(merged1_df, rnaseqmetadata, on='specimenID', how='outer')\n",
    "\n",
    "print(\"\\n=== MERGED DATAFRAME INFO ===\")\n",
    "print(f\"Shape: {merged_df.shape[0]} rows x {merged_df.shape[1]} columns\")\n",
    "print(f\"Columns: {list(merged_df.columns)}\")\n",
    "\n",
    "if 'individualID' in merged_df.columns:\n",
    "    print(f\"Number of unique individualIDs: {merged_df['individualID'].nunique()}\")\n",
    "    print(f\"Number of rows with missing individualID: {merged_df['individualID'].isna().sum()}\")\n",
    "else:\n",
    "    print(\"'individualID' column not found in merged_df.\")\n",
    "\n",
    "if 'specimenID' in merged_df.columns:\n",
    "    print(f\"Number of unique specimenIDs: {merged_df['specimenID'].nunique()}\")\n",
    "    print(f\"Number of rows with missing specimenID: {merged_df['specimenID'].isna().sum()}\")\n",
    "else:\n",
    "    print(\"'specimenID' column not found in merged_df.\")\n",
    "\n",
    "print(\"\\nFirst 5 rows of merged_df:\")\n",
    "print(merged_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unique entries in 'tissue' column:\n",
      "- plasma\n",
      "- cerebral cortex\n",
      "- hippocampus\n",
      "\n",
      "Total unique tissues: 3\n",
      "\n",
      "Unique entries in 'genotype' column:\n",
      "- 5XFAD_carrier, BIN1-K358R_homozygous\n",
      "- 5XFAD_carrier\n",
      "- BIN1-K358R_homozygous\n",
      "- 5XFAD_noncarrier\n",
      "- AppAbeta_LoxP_noncarrier\n",
      "\n",
      "Total unique genotypes: 5\n",
      "\n",
      "Number of entries for each tissue for each genotype:\n",
      "- 5XFAD_carrier:\n",
      "    - cerebral cortex: 65\n",
      "    - hippocampus: 84\n",
      "    - plasma: 21\n",
      "- 5XFAD_carrier, BIN1-K358R_homozygous:\n",
      "    - cerebral cortex: 71\n",
      "    - hippocampus: 85\n",
      "    - plasma: 22\n",
      "- 5XFAD_noncarrier:\n",
      "    - cerebral cortex: 71\n",
      "    - hippocampus: 38\n",
      "    - plasma: 21\n",
      "- AppAbeta_LoxP_noncarrier:\n",
      "    - hippocampus: 22\n",
      "- BIN1-K358R_homozygous:\n",
      "    - cerebral cortex: 74\n",
      "    - hippocampus: 57\n",
      "    - plasma: 22\n",
      "\n",
      "Number of unique (specimenID, individualID) pairs: 653\n"
     ]
    }
   ],
   "source": [
    "# Just looking at some stuff, not neccessary to run\n",
    "# Print unique entries for the \"tissue\" column in merged_df\n",
    "if \"tissue\" in merged_df.columns:\n",
    "    unique_tissues = merged_df[\"tissue\"].dropna().unique()\n",
    "    print(\"\\nUnique entries in 'tissue' column:\")\n",
    "    for t in unique_tissues:\n",
    "        print(f\"- {t}\")\n",
    "    print(f\"\\nTotal unique tissues: {len(unique_tissues)}\")\n",
    "else:\n",
    "    print(\"'tissue' column not found in merged_df.\")\n",
    "\n",
    "# Print unique entries for the \"genotype\" column in merged_df\n",
    "if \"genotype\" in merged_df.columns:\n",
    "    unique_genotypes = merged_df[\"genotype\"].dropna().unique()\n",
    "    print(\"\\nUnique entries in 'genotype' column:\")\n",
    "    for g in unique_genotypes:\n",
    "        print(f\"- {g}\")\n",
    "    print(f\"\\nTotal unique genotypes: {len(unique_genotypes)}\")\n",
    "else:\n",
    "    print(\"'genotype' column not found in merged_df.\")\n",
    "\n",
    "# Print the number of entries for each tissue for each genotype\n",
    "if \"genotype\" in merged_df.columns and \"tissue\" in merged_df.columns:\n",
    "    counts = merged_df.groupby([\"genotype\", \"tissue\"]).size().reset_index(name=\"count\")\n",
    "    print(\"\\nNumber of entries for each tissue for each genotype:\")\n",
    "    if counts.empty:\n",
    "        print(\"No data found for genotype and tissue combinations.\")\n",
    "    else:\n",
    "        for g in counts[\"genotype\"].unique():\n",
    "            print(f\"- {g}:\")\n",
    "            sub = counts[counts[\"genotype\"] == g]\n",
    "            for _, row in sub.iterrows():\n",
    "                print(f\"    - {row['tissue']}: {row['count']}\")\n",
    "else:\n",
    "    print(\"Either 'genotype' or 'tissue' column not found in merged_df.\")\n",
    "\n",
    "# Print the number of unique (specimenID, individualID) pairs in merged_df\n",
    "if 'specimenID' in merged_df.columns and 'individualID' in merged_df.columns:\n",
    "    unique_pairs = merged_df[['specimenID', 'individualID']].drop_duplicates()\n",
    "    print(f\"\\nNumber of unique (specimenID, individualID) pairs: {len(unique_pairs)}\")\n",
    "else:\n",
    "    print(\"Either 'specimenID' or 'individualID' column not found in merged_df.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== GROUPED COUNTS BY ageDeath, sex, genotype ===\n",
      "    ageDeath     sex                              genotype  count\n",
      "0          4  female                         5XFAD_carrier     38\n",
      "1          4  female  5XFAD_carrier, BIN1-K358R_homozygous     42\n",
      "2          4  female                      5XFAD_noncarrier     14\n",
      "3          4  female                 BIN1-K358R_homozygous     21\n",
      "4          4    male                         5XFAD_carrier     42\n",
      "5          4    male  5XFAD_carrier, BIN1-K358R_homozygous     42\n",
      "6          4    male                      5XFAD_noncarrier     22\n",
      "7          4    male                 BIN1-K358R_homozygous     22\n",
      "8         12  female                         5XFAD_carrier     49\n",
      "9         12  female  5XFAD_carrier, BIN1-K358R_homozygous     49\n",
      "10        12  female                      5XFAD_noncarrier     49\n",
      "11        12  female              AppAbeta_LoxP_noncarrier     12\n",
      "12        12  female                 BIN1-K358R_homozygous     53\n",
      "13        12    male                         5XFAD_carrier     41\n",
      "14        12    male  5XFAD_carrier, BIN1-K358R_homozygous     45\n",
      "15        12    male                      5XFAD_noncarrier     45\n",
      "16        12    male              AppAbeta_LoxP_noncarrier     10\n",
      "17        12    male                 BIN1-K358R_homozygous     57\n",
      "\n",
      "Number of unique groups: 18\n"
     ]
    }
   ],
   "source": [
    "# GET THE DATA FOR THE SPREADSHEET (https://docs.google.com/spreadsheets/d/11vmntFrno9ubNMOE8bbMejEROPygmeJZ/edit?pli=1&gid=757405125#gid=757405125)\n",
    "# Group merged_df by \"ageDeath\", \"sex\", and \"genotype\" and count the number of rows in each group\n",
    "grouped = merged_df.groupby([\"ageDeath\", \"sex\", \"genotype\"]).size().reset_index(name='count')\n",
    "\n",
    "print(\"\\n=== GROUPED COUNTS BY ageDeath, sex, genotype ===\")\n",
    "print(grouped)\n",
    "\n",
    "print(f\"\\nNumber of unique groups: {grouped.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate Metadata\n",
    "Look at the actual RNAseq data and make sure that all samples exist and align with what is stated in the metadata.\n",
    "https://www.synapse.org/Synapse:syn50944329"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In terminal, run:\n",
    "# synapse list syn50944329 > UCI_Bin1K358R_rnaseqdata_list.csv\n",
    "\n",
    "df = pd.read_csv(\"UCI_Bin1K358R_rnaseqdata_list.csv\", header=None, names=[\"syn_id\", \"file_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    lane tissue sex   genotype   age individualID read\n",
      "0     B1   hipp   F  5XFADHEMI  12mo        12433   R1\n",
      "1     B1   hipp   F  5XFADHEMI  12mo        12433   R2\n",
      "2     B1   hipp   F  5XFADHEMI  12mo        12440   R1\n",
      "3     B1   hipp   F  5XFADHEMI  12mo        12440   R2\n",
      "4     B1   hipp   F  5XFADHEMI  12mo        12450   R1\n",
      "..   ...    ...  ..        ...   ...          ...  ...\n",
      "143   B1   hipp   M    Bin1_HO   4mo        13037   R2\n",
      "144   B1   hipp   M    Bin1_HO   4mo        13041   R1\n",
      "145   B1   hipp   M    Bin1_HO   4mo        13041   R2\n",
      "146   B1   hipp   M    Bin1_HO   4mo        13045   R1\n",
      "147   B1   hipp   M    Bin1_HO   4mo        13045   R2\n",
      "\n",
      "[148 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "# Parse the filename to get the metadata\n",
    "def parse_filename(fname):\n",
    "    # Split by underscore\n",
    "    parts = str(fname).split(\"_\")\n",
    "    # Defensive: if not enough parts, return Nones\n",
    "    if len(parts) < 7:\n",
    "        return {\n",
    "            \"lane\": None,\n",
    "            \"tissue\": None,\n",
    "            \"sex\": None,\n",
    "            \"genotype\": None,\n",
    "            \"age\": None,\n",
    "            \"individualID\": None,\n",
    "            \"read\": None\n",
    "        }\n",
    "    # Find the index of the sex (first \"M\" or \"F\")\n",
    "    try:\n",
    "        sex_idx = next(i for i, p in enumerate(parts) if p in (\"M\", \"F\"))\n",
    "    except StopIteration:\n",
    "        sex_idx = 1  # fallback, but may be wrong\n",
    "    # Find the index of the age (endswith \"mo\")\n",
    "    try:\n",
    "        age_idx = next(i for i, p in enumerate(parts) if p.endswith(\"mo\"))\n",
    "    except StopIteration:\n",
    "        age_idx = sex_idx + 2  # fallback\n",
    "    # Find the index of the individualID (should be after lane)\n",
    "    try:\n",
    "        indiv_idx = age_idx + 2\n",
    "        individualID = parts[indiv_idx]\n",
    "    except IndexError:\n",
    "        individualID = None\n",
    "    # Find the index of the lane (should be after age)\n",
    "    try:\n",
    "        lane_idx = age_idx + 1\n",
    "        lane = parts[lane_idx]\n",
    "    except IndexError:\n",
    "        lane = None\n",
    "    # Read is always the last part before extension, e.g. ..._1.fq.gz or ..._2.fq.gz\n",
    "    read_part = parts[-1]\n",
    "    # If read_part contains a dot, split and take the first part (e.g. \"1.fq.gz\" -> \"1\")\n",
    "    read = read_part.split(\".\")[0]\n",
    "    # Genotype is everything between sex and age\n",
    "    genotype = \"_\".join(parts[sex_idx + 1:age_idx])\n",
    "    return {\n",
    "        \"lane\": lane,\n",
    "        \"tissue\": parts[0],\n",
    "        \"sex\": parts[sex_idx],\n",
    "        \"genotype\": genotype,\n",
    "        \"age\": parts[age_idx],\n",
    "        \"individualID\": individualID,\n",
    "        \"read\": read\n",
    "    }\n",
    "\n",
    "parsed = df[\"file_name\"].apply(parse_filename)\n",
    "parsed_df = pd.DataFrame(parsed.tolist())\n",
    "print(parsed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All entries have both read=1 and read=2.\n"
     ]
    }
   ],
   "source": [
    "# Make sure all samples have both read1 and read2\n",
    "# For each unique sample (excluding 'read'), check if both read=1 and read=2 exist\n",
    "group_cols = [col for col in parsed_df.columns if col != \"read\"]\n",
    "read_counts = parsed_df.groupby(group_cols)[\"read\"].nunique().reset_index()\n",
    "# Entries where the number of unique reads is not 2 (i.e., missing a read)\n",
    "missing_reads = read_counts[read_counts[\"read\"] != 2]\n",
    "if not missing_reads.empty:\n",
    "    print(\"Entries missing either read=1 or read=2:\")\n",
    "    display(missing_reads)\n",
    "else:\n",
    "    print(\"All entries have both read=1 and read=2.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop read 2\n",
    "# Merge parsed_df back to df to keep all columns\n",
    "merged_df_validation = pd.concat([df.reset_index(drop=True), parsed_df.reset_index(drop=True)], axis=1)\n",
    "\n",
    "# Identify columns to compare for \"exact same value\" (excluding 'read')\n",
    "compare_cols = [col for col in parsed_df.columns if col != \"read\"]\n",
    "\n",
    "# Sort so that read=1 comes before read=2 for duplicates\n",
    "merged_df_sorted = merged_df_validation.sort_values(by=compare_cols + [\"read\"])\n",
    "\n",
    "# Drop duplicates, keeping the first (which will be read=1 if both exist)\n",
    "dedup_df = merged_df_sorted.drop_duplicates(subset=compare_cols, keep=\"first\")\n",
    "\n",
    "new_df = dedup_df[parsed_df.columns].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== GROUPED COUNTS BY age, sex, genotype ===\n",
      "     age sex           genotype  count\n",
      "0   12mo   F          5XFADHEMI      5\n",
      "1   12mo   F  5xFADHEMI_Bin1_HO      5\n",
      "2   12mo   F            5xFADWT      5\n",
      "3   12mo   F             BIN1HO      1\n",
      "4   12mo   F            Bin1_HO      4\n",
      "5   12mo   M          5XFADHEMI      4\n",
      "6   12mo   M  5xFADHEMI_Bin1_HO      5\n",
      "7   12mo   M            5xFADWT      5\n",
      "8   12mo   M            Bin1_HO      5\n",
      "9    4mo   F          5xFADHEMI      5\n",
      "10   4mo   F  5xFADHEMI_Bin1_HO      4\n",
      "11   4mo   F            5xFADWT      2\n",
      "12   4mo   F            Bin1_HO      4\n",
      "13   4mo   M          5xFADHEMI      5\n",
      "14   4mo   M  5xFADHEMI_Bin1_HO      5\n",
      "15   4mo   M            5xFADWT      5\n",
      "16   4mo   M            Bin1_HO      5\n",
      "\n",
      "Number of unique groups: 17\n"
     ]
    }
   ],
   "source": [
    "# Get metadata to compare\n",
    "# Group merged_df by \"age\", \"sex\", and \"genotype\" and count the number of rows in each group\n",
    "grouped = new_df.groupby([\"age\", \"sex\", \"genotype\"]).size().reset_index(name='count')\n",
    "\n",
    "print(\"\\n=== GROUPED COUNTS BY age, sex, genotype ===\")\n",
    "print(grouped)\n",
    "\n",
    "print(f\"\\nNumber of unique groups: {grouped.shape[0]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adt_py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
